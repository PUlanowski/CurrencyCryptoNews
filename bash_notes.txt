#secure copy to EC2
scp -C -i ./pw.ambari.study.pem -r ./'Capstone Project' hadoop@ec2-3-239-92-240.compute-1.amazonaws.com:~/Capstone
#getting pip on EC2
curl -O https://bootstrap.pypa.io/get-pip.py
python get-pip.py
pip install kaggle
cd /home/hadoop/.kaggle
vim kaggle.json
#paste data from downloaded kaggle token
cd ~/.kaggle/kaggle/.json
chmod 600 kaggle.json
cd ~/Capstone/
python fetch_resources.py

### DOCKER RUNS ###

#create spark network overlay
docker network create --driver bridge spark-net-bridge

#postgres run
docker run --network spark-net-bridge --name postgres -e POSTGRES_HOST_AUTH_METHOD=trust -d -p 5432:5432 postgres

#cassandra run
docker run --network spark-net-bridge --name cassie  -d -p 9042:9042 cassandra

#container copy
docker cp "C:\Users\pit\Google Drive\Udacity\Capstone Project\jdbc\postgresql-42.2.5.jar" 9093c9128018:/opt/bitnami/spark/jars/postgresql-42.2.5.jar

#check local network
docker network inspect spark-net-bridge

#attach to container from powershell
docker exec -u 0 -it <container name> bash


#spark runs MASTER
docker run -d --name spark --network spark-net-bridge -p 8080:8080 -p 7077:7077 -e SPARK_MODE=master -e SPARK_RPC_AUTHENTICATION_ENABLED=no -e SPARK_RPC_ENCRYPTION_ENABLED=no -e SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no -e SPARK_SSL_ENABLED=no bitnami/spark:3.0.0

#in Docker Spark Container:
#1. goto /opt/bitnami/spark/sbin
#2. run start-master.sh
#3. start-slave.sh OR start-slaves.sh


#check local network
docker network inspect spark-net-bridge

#spark runs WORKER#1
docker run -d --name sparkW1 --network spark-net-bridge -p 8081:8081 -e SPARK_MODE=worker -e SPARK_MASTER_URL=spark://sparkM:7077 -e SPARK_WORKER_MEMORY=1G -e SPARK_WORKER_CORES=1 -e SPARK_RPC_AUTHENTICATION_ENABLED=no -e SPARK_RPC_ENCRYPTION_ENABLED=no -e SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no -e SPARK_SSL_ENABLED=no bitnami/spark:3.0.0
